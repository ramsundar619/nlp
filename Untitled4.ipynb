{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHF6OqHr2QaWWoUm6NiJZu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramsundar619/nlp/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeFpnBM40qCM",
        "outputId": "05b3ec39-53fc-4a11-c36d-4536d5ccced4"
      },
      "source": [
        "from google.colab import drive                                     #mounting the drive to acces the data stored in google drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhly5Yl-0yti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66420db4-ed36-4365-fa0e-42364f663950"
      },
      "source": [
        "!pip3 install -U spacy\n",
        "!python3 -m spacy download en_core_sci_lg\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "import sys\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from gensim.models import ldamodel\n",
        "import gensim.corpora\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.decomposition import NMF\n",
        "from sklearn.preprocessing import normalize\n",
        "import pickle"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.1.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 5.4 MB/s \n",
            "\u001b[?25hCollecting thinc<8.1.0,>=8.0.8\n",
            "  Downloading thinc-8.0.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (621 kB)\n",
            "\u001b[K     |████████████████████████████████| 621 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.2.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Collecting typer<0.4.0,>=0.3.0\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Collecting srsly<3.0.0,>=2.4.1\n",
            "  Downloading srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[K     |████████████████████████████████| 456 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.6.0-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 48.6 MB/s \n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.7\n",
            "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.4\n",
            "  Downloading catalogue-2.0.4-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Installing collected packages: catalogue, typer, srsly, pydantic, thinc, spacy-legacy, pathy, spacy\n",
            "  Attempting uninstall: catalogue\n",
            "    Found existing installation: catalogue 1.0.0\n",
            "    Uninstalling catalogue-1.0.0:\n",
            "      Successfully uninstalled catalogue-1.0.0\n",
            "  Attempting uninstall: srsly\n",
            "    Found existing installation: srsly 1.0.5\n",
            "    Uninstalling srsly-1.0.5:\n",
            "      Successfully uninstalled srsly-1.0.5\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed catalogue-2.0.4 pathy-0.6.0 pydantic-1.8.2 spacy-3.1.1 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.8 typer-0.3.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "catalogue",
                  "spacy",
                  "srsly",
                  "thinc"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-08-02 12:47:23.340539: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "\u001b[38;5;1m✘ No compatible package found for 'en_core_sci_lg' (spaCy v3.1.1)\u001b[0m\n",
            "\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YByRIIuk1k3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3871e6d5-65a7-463d-c219-6a27b6198e00"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/SentiSum/sentisum-assessment-dataset.csv\");\n",
        "dataDf=pd.DataFrame(data,columns=['Raw Data'])\n",
        "dataDf.head()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tires where delivered to the garage of my choi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Easy Tyre Selection Process, Competitive Prici...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Very easy to use and good value for money.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Really easy and convenient to arrange</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It was so easy to select tyre sizes and arrang...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Raw Data\n",
              "0  Tires where delivered to the garage of my choi...\n",
              "1  Easy Tyre Selection Process, Competitive Prici...\n",
              "2         Very easy to use and good value for money.\n",
              "3              Really easy and convenient to arrange\n",
              "4  It was so easy to select tyre sizes and arrang..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "xAUxODOn4KBH",
        "outputId": "862f6250-51cb-40ba-f419-1667f9cca9d4"
      },
      "source": [
        "dataDf = dataDf.astype('str')\n",
        "nlp = spacy.load(\"en_core_sci_lg\")\n",
        "def dataCleaning(df):\n",
        "    data = df.copy()\n",
        "    data['Raw Data'] = nlp(data['Raw Data'])\n",
        "    return data.ents    "
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-031974b9487d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataDf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataDf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'str'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_sci_lg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdataCleaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Raw Data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Raw Data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdepr_path\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mdeprecation_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW001\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(name, **overrides)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Path or Path-like to model data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE050\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI_F-8OW2PNA"
      },
      "source": [
        "dataDf = dataDf.astype('str')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def tokenize_lemma_stopwords(text):\n",
        "    text = text.replace(\"\\n\", \" \")\n",
        "    # split string into words (tokens)\n",
        "    tokens = nltk.tokenize.word_tokenize(text.lower())\n",
        "    # keep strings with only alphabets\n",
        "    tokens = [t for t in tokens if t.isalpha()]\n",
        "    # put words into base form\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] \n",
        "    tokens = [stemmer.stem(t) for t in tokens]\n",
        "    # remove short words, they're probably not useful\n",
        "    #tokens = [t for t in tokens if len(t) > 2]\n",
        "    tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
        "    cleanedText = \" \".join(tokens)\n",
        "    return cleanedText\n",
        "\n",
        "def dataCleaning(df):\n",
        "    data = df.copy()\n",
        "    data['Raw Data'] =data['Raw Data'].apply(tokenize_lemma_stopwords)\n",
        "    return data"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vDldsFs3k9z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "6228fe2a-0268-4271-c1ac-dec8fb620728"
      },
      "source": [
        "cleaned_Data=dataCleaning(dataDf)\n",
        "cleaned_Data.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tire deliv garag choic garag notifi deliv day ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>easi tyre select process competit price excel ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>veri easi use good valu money</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>realli easi conveni arrang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wa easi select tyre size arrang local fit pric...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Raw Data\n",
              "0  tire deliv garag choic garag notifi deliv day ...\n",
              "1  easi tyre select process competit price excel ...\n",
              "2                      veri easi use good valu money\n",
              "3                         realli easi conveni arrang\n",
              "4  wa easi select tyre size arrang local fit pric..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wl9MAJnoFS8"
      },
      "source": [
        "num_topics=12\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorised_cleaned_Data = vectorizer.fit_transform(cleaned_Data['Raw Data'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVdkzHg0qplD"
      },
      "source": [
        "transformer = TfidfTransformer(smooth_idf=False)\n",
        "Data_tfidf = transformer.fit_transform(vectorised_cleaned_Data)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aj9SlZqMt0s8"
      },
      "source": [
        "Data_tfidf_norm = normalize(Data_tfidf, norm='l1', axis=1)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIWryyYsuCSN",
        "outputId": "24917a70-d574-4cc2-f707-3481e7a54e47"
      },
      "source": [
        "#obtain a NMF model.\n",
        "model = NMF(n_components=num_topics, init='nndsvd');\n",
        "model.fit(Data_tfidf_norm)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMF(alpha=0.0, beta_loss='frobenius', init='nndsvd', l1_ratio=0.0, max_iter=200,\n",
              "    n_components=12, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
              "    verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPpFUaW_uPLL"
      },
      "source": [
        "def get_nmf_topics(model, n_top_words):\n",
        "    \n",
        "    #the word ids obtained need to be reverse-mapped to the words so we can print the topic names.\n",
        "    feat_names = vectorizer.get_feature_names()\n",
        "    \n",
        "    word_dict = {}\n",
        "    for i in range(num_topics):\n",
        "        \n",
        "        #for each topic, obtain the largest values, and add the words they map to into the dictionary.\n",
        "        words_ids = model.components_[i].argsort()[:-20 - 1:-1]\n",
        "        words = [feat_names[key] for key in words_ids]\n",
        "        word_dict['Topic # ' + '{:02d}'.format(i+1)] = words\n",
        "    \n",
        "    return pd.DataFrame(word_dict)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "4C_u5c3F1VhM",
        "outputId": "c5011e8d-60c6-4f10-c6fd-9d44598a2ded"
      },
      "source": [
        "get_nmf_topics(model, 20)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic # 01</th>\n",
              "      <th>Topic # 02</th>\n",
              "      <th>Topic # 03</th>\n",
              "      <th>Topic # 04</th>\n",
              "      <th>Topic # 05</th>\n",
              "      <th>Topic # 06</th>\n",
              "      <th>Topic # 07</th>\n",
              "      <th>Topic # 08</th>\n",
              "      <th>Topic # 09</th>\n",
              "      <th>Topic # 10</th>\n",
              "      <th>Topic # 11</th>\n",
              "      <th>Topic # 12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>good</td>\n",
              "      <td>great</td>\n",
              "      <td>excel</td>\n",
              "      <td>effici</td>\n",
              "      <td>valu</td>\n",
              "      <td>easi</td>\n",
              "      <td>quick</td>\n",
              "      <td>competit</td>\n",
              "      <td>simpl</td>\n",
              "      <td>fast</td>\n",
              "      <td>hassl</td>\n",
              "      <td>conveni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>price</td>\n",
              "      <td>servic</td>\n",
              "      <td>servic</td>\n",
              "      <td>veri</td>\n",
              "      <td>money</td>\n",
              "      <td>use</td>\n",
              "      <td>reliabl</td>\n",
              "      <td>price</td>\n",
              "      <td>process</td>\n",
              "      <td>reliabl</td>\n",
              "      <td>free</td>\n",
              "      <td>cheap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>servic</td>\n",
              "      <td>price</td>\n",
              "      <td>price</td>\n",
              "      <td>servic</td>\n",
              "      <td>good</td>\n",
              "      <td>websit</td>\n",
              "      <td>cheap</td>\n",
              "      <td>veri</td>\n",
              "      <td>straightforward</td>\n",
              "      <td>friendli</td>\n",
              "      <td>brilliant</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>veri</td>\n",
              "      <td>tyre</td>\n",
              "      <td>recommend</td>\n",
              "      <td>profession</td>\n",
              "      <td>brilliant</td>\n",
              "      <td>order</td>\n",
              "      <td>easi</td>\n",
              "      <td>local</td>\n",
              "      <td>veri</td>\n",
              "      <td>deliveri</td>\n",
              "      <td>problem</td>\n",
              "      <td>veri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>choic</td>\n",
              "      <td>alway</td>\n",
              "      <td>thank</td>\n",
              "      <td>friendli</td>\n",
              "      <td>arrang</td>\n",
              "      <td>veri</td>\n",
              "      <td>servic</td>\n",
              "      <td>choic</td>\n",
              "      <td>profession</td>\n",
              "      <td>servic</td>\n",
              "      <td>purchas</td>\n",
              "      <td>locat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>tyre</td>\n",
              "      <td>choic</td>\n",
              "      <td>custom</td>\n",
              "      <td>prompt</td>\n",
              "      <td>save</td>\n",
              "      <td>book</td>\n",
              "      <td>reason</td>\n",
              "      <td>tyre</td>\n",
              "      <td>realli</td>\n",
              "      <td>profession</td>\n",
              "      <td>fuss</td>\n",
              "      <td>eas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>garag</td>\n",
              "      <td>custom</td>\n",
              "      <td>would</td>\n",
              "      <td>polit</td>\n",
              "      <td>great</td>\n",
              "      <td>process</td>\n",
              "      <td>friendli</td>\n",
              "      <td>garag</td>\n",
              "      <td>system</td>\n",
              "      <td>reason</td>\n",
              "      <td>experi</td>\n",
              "      <td>price</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>problem</td>\n",
              "      <td>qualiti</td>\n",
              "      <td>tyre</td>\n",
              "      <td>well</td>\n",
              "      <td>qualiti</td>\n",
              "      <td>definit</td>\n",
              "      <td>deliveri</td>\n",
              "      <td>fitter</td>\n",
              "      <td>order</td>\n",
              "      <td>staff</td>\n",
              "      <td>fit</td>\n",
              "      <td>fit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>local</td>\n",
              "      <td>thank</td>\n",
              "      <td>fit</td>\n",
              "      <td>thank</td>\n",
              "      <td>choic</td>\n",
              "      <td>local</td>\n",
              "      <td>veri</td>\n",
              "      <td>help</td>\n",
              "      <td>nice</td>\n",
              "      <td>qualiti</td>\n",
              "      <td>time</td>\n",
              "      <td>choic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>fitter</td>\n",
              "      <td>fantast</td>\n",
              "      <td>round</td>\n",
              "      <td>effect</td>\n",
              "      <td>local</td>\n",
              "      <td>fit</td>\n",
              "      <td>qualiti</td>\n",
              "      <td>option</td>\n",
              "      <td>use</td>\n",
              "      <td>recommend</td>\n",
              "      <td>recommend</td>\n",
              "      <td>reason</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>fit</td>\n",
              "      <td>garag</td>\n",
              "      <td>use</td>\n",
              "      <td>cost</td>\n",
              "      <td>better</td>\n",
              "      <td>arrang</td>\n",
              "      <td>profession</td>\n",
              "      <td>fit</td>\n",
              "      <td>save</td>\n",
              "      <td>help</td>\n",
              "      <td>troubl</td>\n",
              "      <td>time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>qualiti</td>\n",
              "      <td>experi</td>\n",
              "      <td>qualiti</td>\n",
              "      <td>alway</td>\n",
              "      <td>transact</td>\n",
              "      <td>choic</td>\n",
              "      <td>respons</td>\n",
              "      <td>book</td>\n",
              "      <td>start</td>\n",
              "      <td>prompt</td>\n",
              "      <td>book</td>\n",
              "      <td>local</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>experi</td>\n",
              "      <td>use</td>\n",
              "      <td>garag</td>\n",
              "      <td>realli</td>\n",
              "      <td>seem</td>\n",
              "      <td>garag</td>\n",
              "      <td>highli</td>\n",
              "      <td>product</td>\n",
              "      <td>finish</td>\n",
              "      <td>effect</td>\n",
              "      <td>tyre</td>\n",
              "      <td>tyre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>reason</td>\n",
              "      <td>recommend</td>\n",
              "      <td>highli</td>\n",
              "      <td>best</td>\n",
              "      <td>sevic</td>\n",
              "      <td>best</td>\n",
              "      <td>effect</td>\n",
              "      <td>reason</td>\n",
              "      <td>smooth</td>\n",
              "      <td>job</td>\n",
              "      <td>best</td>\n",
              "      <td>way</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>product</td>\n",
              "      <td>fitter</td>\n",
              "      <td>fitter</td>\n",
              "      <td>round</td>\n",
              "      <td>reliabl</td>\n",
              "      <td>site</td>\n",
              "      <td>decent</td>\n",
              "      <td>eas</td>\n",
              "      <td>problem</td>\n",
              "      <td>highli</td>\n",
              "      <td>would</td>\n",
              "      <td>place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>alway</td>\n",
              "      <td>local</td>\n",
              "      <td>definit</td>\n",
              "      <td>smooth</td>\n",
              "      <td>process</td>\n",
              "      <td>realli</td>\n",
              "      <td>brilliant</td>\n",
              "      <td>straightforward</td>\n",
              "      <td>buy</td>\n",
              "      <td>fault</td>\n",
              "      <td>straightforward</td>\n",
              "      <td>like</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>commun</td>\n",
              "      <td>time</td>\n",
              "      <td>brilliant</td>\n",
              "      <td>recommend</td>\n",
              "      <td>fantast</td>\n",
              "      <td>would</td>\n",
              "      <td>staff</td>\n",
              "      <td>profession</td>\n",
              "      <td>alway</td>\n",
              "      <td>time</td>\n",
              "      <td>futur</td>\n",
              "      <td>garag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>prompt</td>\n",
              "      <td>fault</td>\n",
              "      <td>fault</td>\n",
              "      <td>help</td>\n",
              "      <td>deal</td>\n",
              "      <td>time</td>\n",
              "      <td>order</td>\n",
              "      <td>servic</td>\n",
              "      <td>fit</td>\n",
              "      <td>realli</td>\n",
              "      <td>got</td>\n",
              "      <td>choos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>help</td>\n",
              "      <td>commun</td>\n",
              "      <td>alway</td>\n",
              "      <td>experi</td>\n",
              "      <td>partner</td>\n",
              "      <td>recommend</td>\n",
              "      <td>onlin</td>\n",
              "      <td>select</td>\n",
              "      <td>effect</td>\n",
              "      <td>fuss</td>\n",
              "      <td>local</td>\n",
              "      <td>onlin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>fair</td>\n",
              "      <td>best</td>\n",
              "      <td>profession</td>\n",
              "      <td>would</td>\n",
              "      <td>everi</td>\n",
              "      <td>choos</td>\n",
              "      <td>polit</td>\n",
              "      <td>rang</td>\n",
              "      <td>arrang</td>\n",
              "      <td>definit</td>\n",
              "      <td>redact</td>\n",
              "      <td>buy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Topic # 01 Topic # 02  Topic # 03  ...  Topic # 10       Topic # 11 Topic # 12\n",
              "0        good      great       excel  ...        fast            hassl    conveni\n",
              "1       price     servic      servic  ...     reliabl             free      cheap\n",
              "2      servic      price       price  ...    friendli        brilliant       best\n",
              "3        veri       tyre   recommend  ...    deliveri          problem       veri\n",
              "4       choic      alway       thank  ...      servic          purchas      locat\n",
              "5        tyre      choic      custom  ...  profession             fuss        eas\n",
              "6       garag     custom       would  ...      reason           experi      price\n",
              "7     problem    qualiti        tyre  ...       staff              fit        fit\n",
              "8       local      thank         fit  ...     qualiti             time      choic\n",
              "9      fitter    fantast       round  ...   recommend        recommend     reason\n",
              "10        fit      garag         use  ...        help           troubl       time\n",
              "11    qualiti     experi     qualiti  ...      prompt             book      local\n",
              "12     experi        use       garag  ...      effect             tyre       tyre\n",
              "13     reason  recommend      highli  ...         job             best        way\n",
              "14    product     fitter      fitter  ...      highli            would      place\n",
              "15      alway      local     definit  ...       fault  straightforward       like\n",
              "16     commun       time   brilliant  ...        time            futur      garag\n",
              "17     prompt      fault       fault  ...      realli              got      choos\n",
              "18       help     commun       alway  ...        fuss            local      onlin\n",
              "19       fair       best  profession  ...     definit           redact        buy\n",
              "\n",
              "[20 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_DYXt7P1hRy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}